from pyspark.sql import SparkSession
import os
import shutil

# create SparkSession
spark= SparkSession.builder.appName("extact_csv").getOrCreate()

# read the file .csv
df= spark.read.csv("data/car_prices.csv",header=True, inferSchema=True)
df.show()
print(type(df))

# save in a only file .csv
output_folder="data/processed/cars_raw"
df.coalesce(1).write.csv(output_folder, header=True, mode= "overwrite")

# rename the generated file
final_filename="cars_raw.csv"

# Find the file inside the folder and rename it
for file in os.listdir(output_folder):
    if file.startswith("part-") and file.endswith(".csv"):
        shutil.move(os.path.join(output_folder, file), os.path.join("data/raw", final_filename))
        break

# Delete the empty folder generated by pyspark
shutil.rmtree(output_folder)

# finally spark
spark.stop()
